{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQw7uz_95F_M"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following cell, if the test version is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UlLWrMwGB6O",
    "outputId": "344fee9a-4d9c-407b-cdbf-6f91e32ea221"
   },
   "outputs": [],
   "source": [
    "%pip install biopython\n",
    "%pip install Levenshtein\n",
    "%pip install gensim\n",
    "%pip install pyjarowinkler\n",
    "\n",
    "%pip install --index-url https://test.pypi.org/simple/ --no-deps --force-reinstall corpus_distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following cell, if the release version is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install corpus_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6eN1lVSV5Lcf"
   },
   "outputs": [],
   "source": [
    "import corpus_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0i4GXBd75O9R"
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NP9ihxYOyc4P"
   },
   "outputs": [],
   "source": [
    "CONTENT_DIR = \"/texts/OES_texts_only/\"\n",
    "STORAGE_DIR = \"exp_1\"\n",
    "TOPIC_NORMALISATION = True\n",
    "SPLIT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(STORAGE_DIR):\n",
    "    os.mkdir(STORAGE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JojHkocENSt"
   },
   "source": [
    "Texts (or collections of texts) should be pre-tokenised single strings, (optionally) stored in separate files. Filenames should contain lect name before extension, split by '.'. For example, 'Akimov.Belogornoje.txt', where *Akimov* is a text name, *Belogornoje* is a lect name, and *txt* is an extension.\n",
    "\n",
    "Texts become dictionary keys, and lects names - its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNc9LBlEyg-d"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.data_preprocessing.data_loading import load_data\n",
    "df = load_data(CONTENT_DIR, SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6fxU4IcFYvV"
   },
   "source": [
    "The next stage is transformation of dictionary into a dataframe of the following format:\n",
    "\n",
    "| index | text | lect |\n",
    "| -------- | ------- |------- |\n",
    "| 0 | text1 | lect1 |\n",
    "| 1 | text2 | lect1 |\n",
    "| 2 | text1 | lect2 |\n",
    "| ... | ... | ... |\n",
    "| m | textN | lectK |\n",
    "\n",
    "*m* here represents the overall number of texts, *K* - the overall number of lects, and *N* is the number of texts in lect *K*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "XDD3-TwOb83B",
    "outputId": "79458141-8913-4fd1-a0e8-88018e6c080b"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i74_OWtr5kfZ"
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFU3meo4g5gp"
   },
   "source": [
    "Here we get lect names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vw3B0c9No0O4"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.cdutils import get_lects_from_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8AO985coy4x"
   },
   "outputs": [],
   "source": [
    "lects = get_lects_from_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VF4WEmvqqKty",
    "outputId": "be7b20c5-93c2-45f1-8e1a-1648f35043c9"
   },
   "outputs": [],
   "source": [
    "lects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7X6mFQ70MgWE"
   },
   "source": [
    "## Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3bEPAVTg8RL"
   },
   "source": [
    "Topic modelling is used to delete topic words that reflect the features of the texts, and not the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ju4G0yPYM3WV"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.data_preprocessing.topic_modelling import get_topic_words_for_lects, add_topic_modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words = get_topic_words_for_lects(df, lects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_topics = add_topic_modelling(df, STORAGE_DIR, topic_words, 'substitute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FhvqFCrJudRS",
    "outputId": "1e13bf55-5095-40dc-df51-f4299e8d001e"
   },
   "outputs": [],
   "source": [
    "df_without_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnFxN5PR5ny3"
   },
   "source": [
    "## Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUy5revgRJx5"
   },
   "source": [
    "I start with creating a model for representing key properties of the lect:\n",
    "\n",
    "* Its name\n",
    "* Text it contains, lowercased\n",
    "* Its alphabet (with obligatory CLS `^` and EOS `$` symbols)\n",
    "* Amount of enthropy of its alphabet\n",
    "* Vector for each given symbol of alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkXzRHyvsS21"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.data_preprocessing.vectorisation import create_vectors_for_lects, gather_vector_information, FastTextParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hL_YztWKqqI2",
    "outputId": "b8f7d271-4c0f-49c3-8928-805fc9473fdb"
   },
   "outputs": [],
   "source": [
    "vectors_for_lects = create_vectors_for_lects(df_without_topics, FastTextParams(seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0OxjYG-sveL"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APhPLjKg5cUB",
    "outputId": "3c13e62b-fd8e-4b54-f516-59494012841b"
   },
   "outputs": [],
   "source": [
    "pprint(vectors_for_lects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfV9w9IHA9o8"
   },
   "source": [
    "# Date preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7tc-8VxE-nz"
   },
   "source": [
    "The first stage of data preprocessing is splitting tokens into character 3-grams. The character n-grams help to find coinciding sequences more easily, than tokens or token n-grams. Specifically 3-grams help to underscore the exact places where the change is happening, providing minimal left and right context for each symbol within the sequence. Adding special symbols *^* and *$* to the start and the end of each sequence helps to do this for the first and the last symbol of the given sequence as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0OFGXEbs2nl"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.data_preprocessing.shingle_processing import split_lects_by_n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5C9QTfagb9x5"
   },
   "outputs": [],
   "source": [
    "df_with_n_grams = split_lects_by_n_grams(df_without_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yC_1p94MKCmg"
   },
   "source": [
    "New dataframe is in the following format:\n",
    "\n",
    "| index | lect | n-gram array |\n",
    "| -------- | ------- |------- |\n",
    "| 0 | lect1 | n-grams of lect1 |\n",
    "| 1 | lect1 | n-grams of lect1 |\n",
    "| ... | ... | ... |\n",
    "| k | lectK | n-grams of lect lectK |\n",
    "\n",
    "Here, *k* is overall number of lects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "u8MDVOsHddap",
    "outputId": "95c8f6db-78ba-428f-aacf-03eaf8dd92c0"
   },
   "outputs": [],
   "source": [
    "df_with_n_grams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1TQvhnPLbom"
   },
   "source": [
    "The next step is to rank n-grams by frequency. The results form *frequency_arranged_n_grams* column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSJ60FhttvHP"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.data_preprocessing.frequency_scoring import count_n_grams_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZHTm7ZEVo5e"
   },
   "outputs": [],
   "source": [
    "df_new = count_n_grams_frequencies(df_with_n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwtQ4xwoMoo-"
   },
   "outputs": [],
   "source": [
    "# add information on letter vectors and alphabet information to dataframe\n",
    "\n",
    "df_new = gather_vector_information(df_new, vectors_for_lects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "MJNi_14rkPhs",
    "outputId": "53224409-3381-44ab-e629-1040e5642124"
   },
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f2Cvp07CCry"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE9YpEaxM0TV"
   },
   "source": [
    "First step is to introduce a measure for hybridisation.\n",
    "\n",
    "One possible measure is scoring Euclidean distance between sum of letter vectors for each n-gram. This results in a loss of order within n-gram, which can yield possible disadvantages (bra === bar), when the measure is used alone; however, when joined with DistRank and Jaro distance, hopefully they yield better results.\n",
    "\n",
    "Optional normalisation includes using alphabet information difference, calculated via subtraction of the second alphabet information from the first one. This allows to compensate for the cases, when letter from one alphabet may have multiple correspondences in the other, depending on the context. Direct (and not reversed, `1 - X`) measure is better, because the more information one alphabet carries, when contrasted to the other, the more possible one-to-many correspondences there are, the more distortions in vectors there are, the more normalisation is needed.\n",
    "\n",
    "Final normalisation includes traditional split by maximal length of two strings, introduced in Holman et al. (2008)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxS7yw4avQkI"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.distance_measurement.string_similarity import *\n",
    "from corpus_distance.distance_measurement.hybridisation import HybridisationParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrFVaCdmvH7M"
   },
   "outputs": [],
   "source": [
    "# assigning global values\n",
    "# group of languages  and its outgroup\n",
    "GROUP = \"Old East Slavic\"\n",
    "OUTGROUP = \"Novgorod\"\n",
    "\n",
    "# if hybrid metrics aids DistRank\n",
    "HYBRIDISATION = True\n",
    "# if hybrid values join DistRank values in a single array, or they both are\n",
    "# independent values, equally contributing to the final metric\n",
    "HYBRIDISATION_AS_ARRAY = True\n",
    "\n",
    "# if distrank normalisation includes soerensen coefficient\n",
    "SOERENSEN_NORMALISATION = True\n",
    "\n",
    "# choose a metric for hybridisation\n",
    "HYBRID = weighted_jaro_winkler_wrapper\n",
    "\n",
    "# if string similarity measure includes correction by\n",
    "# difference in the information that alphabets carry\n",
    "ALPHABET_NORMALISATION = True\n",
    "\n",
    "# metric description\n",
    "METRICS = f\"{GROUP}-{SPLIT}-{TOPIC_NORMALISATION}-DistRank-{SOERENSEN_NORMALISATION}-{HYBRIDISATION}-{HYBRIDISATION_AS_ARRAY}-{HYBRID.__name__}-{ALPHABET_NORMALISATION}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsK5tj2ewfgL"
   },
   "outputs": [],
   "source": [
    "hybridisation_parameters = HybridisationParameters(HYBRIDISATION, SOERENSEN_NORMALISATION, HYBRIDISATION_AS_ARRAY, HYBRID, ALPHABET_NORMALISATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EJY_Rn-DiLTz",
    "outputId": "8a1a9fa1-4838-433d-cccd-96b01540b9d5"
   },
   "outputs": [],
   "source": [
    "METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bdWdnbAv1gE"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.distance_measurement.metrics_pipeline import score_metrics_for_corpus_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xOwwG54CEJD",
    "outputId": "ddfabedf-72ab-4a34-8919-1bf65bf3539f"
   },
   "outputs": [],
   "source": [
    "# declare arrays\n",
    "# calculate distances for each pair of lects\n",
    "overall_results = score_metrics_for_corpus_dataset(df_new, STORAGE_DIR, METRICS, hybridisation_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkJIqBNM0tUt"
   },
   "source": [
    "# Clusterisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FX8ByiTMiQiE"
   },
   "source": [
    "The final step is to cluster the lects into groups, and to decide, whether the method works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsBu1_Og0wD9"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.clusterisation.clusterisation import ClusterisationParameters, clusterise_lects_from_distance_matrix\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6v_o5hq1LYS"
   },
   "outputs": [],
   "source": [
    "cluster_params = ClusterisationParameters(lects, OUTGROUP, GROUP, METRICS, DistanceTreeConstructor().upgma, STORAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-EL_T3Q7Dwt"
   },
   "outputs": [],
   "source": [
    "clusterise_lects_from_distance_matrix(overall_results, cluster_params)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lemmatiser-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
