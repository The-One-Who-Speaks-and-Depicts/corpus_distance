{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQw7uz_95F_M"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UlLWrMwGB6O",
    "outputId": "344fee9a-4d9c-407b-cdbf-6f91e32ea221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: corpus_distance in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (0.5)\n",
      "Requirement already satisfied: scipy==1.11.4 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from corpus_distance) (1.11.4)\n",
      "Requirement already satisfied: biopython==1.83 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from corpus_distance) (1.83)\n",
      "Requirement already satisfied: Levenshtein==0.25.0 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from corpus_distance) (0.25.0)\n",
      "Requirement already satisfied: pandas==2.1.1 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from corpus_distance) (2.1.1)\n",
      "Requirement already satisfied: numpy==1.26.0 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from corpus_distance) (1.26.0)\n",
      "Requirement already satisfied: gensim==4.3.2 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from corpus_distance) (4.3.2)\n",
      "Requirement already satisfied: setuptools>=67.7.2 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from corpus_distance) (70.0.0)\n",
      "Requirement already satisfied: matplotlib==3.7.1 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from corpus_distance) (3.7.1)\n",
      "Requirement already satisfied: pyjarowinkler==1.8 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from corpus_distance) (1.8)\n",
      "Requirement already satisfied: tqdm==4.66.4 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from corpus_distance) (4.66.4)\n",
      "Requirement already satisfied: packaging==21.3 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from corpus_distance) (21.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from gensim==4.3.2->corpus_distance) (7.0.4)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from Levenshtein==0.25.0->corpus_distance) (3.9.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from matplotlib==3.7.1->corpus_distance) (4.53.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from matplotlib==3.7.1->corpus_distance) (1.2.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from matplotlib==3.7.1->corpus_distance) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from matplotlib==3.7.1->corpus_distance) (3.1.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from matplotlib==3.7.1->corpus_distance) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from matplotlib==3.7.1->corpus_distance) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from matplotlib==3.7.1->corpus_distance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from pandas==2.1.1->corpus_distance) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from pandas==2.1.1->corpus_distance) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.7.1->corpus_distance) (1.16.0)\n",
      "Requirement already satisfied: wrapt in /home/ilia/coding/venvs/lemmatiser-venv/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim==4.3.2->corpus_distance) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install corpus_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "id": "6eN1lVSV5Lcf"
   },
   "outputs": [],
   "source": [
    "import corpus_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0i4GXBd75O9R"
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "id": "NP9ihxYOyc4P"
   },
   "outputs": [],
   "source": [
    "CONTENT_DIR = \"/home/ilia/Дакументы/PhD HSE/источники/texts/OES\"\n",
    "TOPIC_NORMALISATION = True\n",
    "SPLIT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JojHkocENSt"
   },
   "source": [
    "Texts (or collections of texts) should be pre-tokenised single strings, (optionally) stored in separate files. Filenames should contain lect name before extension, split by '.'. For example, 'Akimov.Belogornoje.txt', where *Akimov* is a text name, *Belogornoje* is a lect name, and *txt* is an extension.\n",
    "\n",
    "Texts become dictionary keys, and lects names - its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "id": "tNc9LBlEyg-d"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.data_preprocessing.data_loading import load_data\n",
    "df = load_data(CONTENT_DIR, SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6fxU4IcFYvV"
   },
   "source": [
    "The next stage is transformation of dictionary into a dataframe of the following format:\n",
    "\n",
    "| index | text | lect |\n",
    "| -------- | ------- |------- |\n",
    "| 0 | text1 | lect1 |\n",
    "| 1 | text2 | lect1 |\n",
    "| 2 | text1 | lect2 |\n",
    "| ... | ... | ... |\n",
    "| m | textN | lectK |\n",
    "\n",
    "*m* here represents the overall number of texts, *K* - the overall number of lects, and *N* is the number of texts in lect *K*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "XDD3-TwOb83B",
    "outputId": "79458141-8913-4fd1-a0e8-88018e6c080b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>се язъ князь ярославъ володимѣричь , сгадавъ с...</td>\n",
       "      <td>Novgorod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿ⴕ поклонъ и бласловлѣнье • ѡт ѧкова епискупа ...</td>\n",
       "      <td>Polotsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>﻿с азъ, андрѣи данильѥвичь . ажо ми сѧ оучинит...</td>\n",
       "      <td>Polotsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>﻿се язъ кнѧзь смоленьскыи федоръ • сѹдилъ есмь...</td>\n",
       "      <td>Smolensk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>се азъ кнѧзь ѡлександръ и сынъ мои дмитрии с п...</td>\n",
       "      <td>Novgorod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      lect\n",
       "0  се язъ князь ярославъ володимѣричь , сгадавъ с...  Novgorod\n",
       "1  ﻿ⴕ поклонъ и бласловлѣнье • ѡт ѧкова епискупа ...   Polotsk\n",
       "2  ﻿с азъ, андрѣи данильѥвичь . ажо ми сѧ оучинит...   Polotsk\n",
       "3  ﻿се язъ кнѧзь смоленьскыи федоръ • сѹдилъ есмь...  Smolensk\n",
       "4  се азъ кнѧзь ѡлександръ и сынъ мои дмитрии с п...  Novgorod"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i74_OWtr5kfZ"
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFU3meo4g5gp"
   },
   "source": [
    "Here we get lect names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "id": "vw3B0c9No0O4"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.cdutils import get_lects_from_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "id": "b8AO985coy4x"
   },
   "outputs": [],
   "source": [
    "lects = get_lects_from_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VF4WEmvqqKty",
    "outputId": "be7b20c5-93c2-45f1-8e1a-1648f35043c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Novgorod', 'Polotsk', 'Smolensk']"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7X6mFQ70MgWE"
   },
   "source": [
    "## Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3bEPAVTg8RL"
   },
   "source": [
    "Topic modelling is used to delete topic words that reflect the features of the texts, and not the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "id": "ju4G0yPYM3WV"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.data_preprocessing.topic_modelling import get_topic_words_for_lects, add_thematic_modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lRVL3sdTorT7",
    "outputId": "f74da9bb-949a-4d80-c754-da2b969a996e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:no word id mapping provided; initializing from corpus, assuming identity\n",
      "WARNING:gensim.models.ldamodel:no word id mapping provided; initializing from corpus, assuming identity\n",
      "WARNING:gensim.models.ldamodel:no word id mapping provided; initializing from corpus, assuming identity\n"
     ]
    }
   ],
   "source": [
    "topic_words = get_topic_words_for_lects(df, lects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "id": "bW_36lwauVkc"
   },
   "outputs": [],
   "source": [
    "df_without_topics = add_thematic_modelling(df, topic_words, TOPIC_NORMALISATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FhvqFCrJudRS",
    "outputId": "1e13bf55-5095-40dc-df51-f4299e8d001e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lect</th>\n",
       "      <th>text_topic_normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>се язъ князь ярославъ володимѣричь сгадавъ пос...</td>\n",
       "      <td>Novgorod</td>\n",
       "      <td>се язъ князь ярославъ володимѣричь сгадавъ пос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿ⴕ поклонъ бласловлѣнье ѡт ѧкова епискупа поло...</td>\n",
       "      <td>Polotsk</td>\n",
       "      <td>﻿ⴕ поклонъ бласловлѣнье ѡт ѧкова епискупа поло...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>﻿с азъ, андрѣи данильѥвичь ажо ми оучинить быт...</td>\n",
       "      <td>Polotsk</td>\n",
       "      <td>﻿с азъ, андрѣи данильѥвичь ажо ми оучинить быт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>﻿се язъ кнѧзь смоленьскыи федоръ сѹдилъ есмь б...</td>\n",
       "      <td>Smolensk</td>\n",
       "      <td>﻿се язъ кнѧзь смоленьскыи федоръ сѹдилъ есмь б...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>се азъ кнѧзь ѡлександръ сынъ мои дмитрии посад...</td>\n",
       "      <td>Novgorod</td>\n",
       "      <td>се азъ кнѧзь ѡлександръ сынъ мои дмитрии посад...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      lect  \\\n",
       "0  се язъ князь ярославъ володимѣричь сгадавъ пос...  Novgorod   \n",
       "1  ﻿ⴕ поклонъ бласловлѣнье ѡт ѧкова епискупа поло...   Polotsk   \n",
       "2  ﻿с азъ, андрѣи данильѥвичь ажо ми оучинить быт...   Polotsk   \n",
       "3  ﻿се язъ кнѧзь смоленьскыи федоръ сѹдилъ есмь б...  Smolensk   \n",
       "4  се азъ кнѧзь ѡлександръ сынъ мои дмитрии посад...  Novgorod   \n",
       "\n",
       "                               text_topic_normalised  \n",
       "0  се язъ князь ярославъ володимѣричь сгадавъ пос...  \n",
       "1  ﻿ⴕ поклонъ бласловлѣнье ѡт ѧкова епискупа поло...  \n",
       "2  ﻿с азъ, андрѣи данильѥвичь ажо ми оучинить быт...  \n",
       "3  ﻿се язъ кнѧзь смоленьскыи федоръ сѹдилъ есмь б...  \n",
       "4  се азъ кнѧзь ѡлександръ сынъ мои дмитрии посад...  "
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnFxN5PR5ny3"
   },
   "source": [
    "## Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUy5revgRJx5"
   },
   "source": [
    "I start with creating a model for representing key properties of the lect:\n",
    "\n",
    "* Its name\n",
    "* Text it contains, lowercased\n",
    "* Its alphabet (with obligatory CLS `^` and EOS `$` symbols)\n",
    "* Amount of enthropy of its alphabet\n",
    "* Vector for each given symbol of alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "id": "AkXzRHyvsS21"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.data_preprocessing.vectorisation import create_vectors_for_lects, gather_vector_information, FastTextParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hL_YztWKqqI2",
    "outputId": "b8f7d271-4c0f-49c3-8928-805fc9473fdb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "vectors_for_lects = create_vectors_for_lects(df_without_topics, FastTextParams(seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "id": "y0OxjYG-sveL"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APhPLjKg5cUB",
    "outputId": "3c13e62b-fd8e-4b54-f516-59494012841b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Novgorod': <corpus_distance.data_preprocessing.vectorisation.Lect object at 0x7e8f330253f0>,\n",
      " 'Polotsk': <corpus_distance.data_preprocessing.vectorisation.Lect object at 0x7e8f32fa0820>,\n",
      " 'Smolensk': <corpus_distance.data_preprocessing.vectorisation.Lect object at 0x7e8f32c74760>}\n"
     ]
    }
   ],
   "source": [
    "pprint(vectors_for_lects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfV9w9IHA9o8"
   },
   "source": [
    "# Date preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7tc-8VxE-nz"
   },
   "source": [
    "The first stage of data preprocessing is splitting tokens into character 3-grams. The character n-grams help to find coinciding sequences more easily, than tokens or token n-grams. Specifically 3-grams help to underscore the exact places where the change is happening, providing minimal left and right context for each symbol within the sequence. Adding special symbols *^* and *$* to the start and the end of each sequence helps to do this for the first and the last symbol of the given sequence as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "id": "X0OFGXEbs2nl"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.data_preprocessing.shingle_processing import split_lects_by_n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "id": "5C9QTfagb9x5"
   },
   "outputs": [],
   "source": [
    "df_with_n_grams = split_lects_by_n_grams(df_without_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yC_1p94MKCmg"
   },
   "source": [
    "New dataframe is in the following format:\n",
    "\n",
    "| index | lect | n-gram array |\n",
    "| -------- | ------- |------- |\n",
    "| 0 | lect1 | n-grams of lect1 |\n",
    "| 1 | lect1 | n-grams of lect1 |\n",
    "| ... | ... | ... |\n",
    "| k | lectK | n-grams of lect lectK |\n",
    "\n",
    "Here, *k* is overall number of lects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "u8MDVOsHddap",
    "outputId": "95c8f6db-78ba-428f-aacf-03eaf8dd92c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lect</th>\n",
       "      <th>n_grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novgorod</td>\n",
       "      <td>[^се, се$, ^яз, язъ, зъ$, ^кн, кня, няз, язь, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polotsk</td>\n",
       "      <td>[^ⴕ$, ^по, пок, окл, кло, лон, онъ, нъ$, ^бл, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smolensk</td>\n",
       "      <td>[^се, се$, ^яз, язъ, зъ$, ^кн, кнѧ, нѧз, ѧзь, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lect                                            n_grams\n",
       "0  Novgorod  [^се, се$, ^яз, язъ, зъ$, ^кн, кня, няз, язь, ...\n",
       "1   Polotsk  [^ⴕ$, ^по, пок, окл, кло, лон, онъ, нъ$, ^бл, ...\n",
       "2  Smolensk  [^се, се$, ^яз, язъ, зъ$, ^кн, кнѧ, нѧз, ѧзь, ..."
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_n_grams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1TQvhnPLbom"
   },
   "source": [
    "The next step is to rank n-grams by frequency. The results form *frequency_arranged_n_grams* column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "id": "hSJ60FhttvHP"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.data_preprocessing.frequency_scoring import count_n_grams_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "id": "sZHTm7ZEVo5e"
   },
   "outputs": [],
   "source": [
    "df_new = count_n_grams_frequencies(df_with_n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "id": "rwtQ4xwoMoo-"
   },
   "outputs": [],
   "source": [
    "# add information on letter vectors and alphabet information to dataframe\n",
    "\n",
    "df_new = gather_vector_information(df_new, vectors_for_lects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "MJNi_14rkPhs",
    "outputId": "53224409-3381-44ab-e629-1040e5642124"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lect</th>\n",
       "      <th>n_grams</th>\n",
       "      <th>frequency_arranged_n_grams</th>\n",
       "      <th>relative_frequency_n_grams</th>\n",
       "      <th>lect_vectors</th>\n",
       "      <th>lect_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novgorod</td>\n",
       "      <td>[^се, се$, ^яз, язъ, зъ$, ^кн, кня, няз, язь, ...</td>\n",
       "      <td>[(оро, 0), (^по, 1), (ть$, 2), (нов, 3), (мъ$,...</td>\n",
       "      <td>[(оро, 0.25), (^по, 0.2504887585532747), (ть$,...</td>\n",
       "      <td>{'^': [0.13765854, -0.04985554, -0.09496442, -...</td>\n",
       "      <td>4.585542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polotsk</td>\n",
       "      <td>[^ⴕ$, ^по, пок, окл, кло, лон, онъ, нъ$, ^бл, ...</td>\n",
       "      <td>[(^по, 0), (ти$, 1), (пол, 2), (мъ$, 3), (^пр,...</td>\n",
       "      <td>[(^по, 0.25), (ти$, 0.2504916420845624), (пол,...</td>\n",
       "      <td>{'^': [0.00029285578, -0.17601506, -0.08750519...</td>\n",
       "      <td>4.511540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smolensk</td>\n",
       "      <td>[^се, се$, ^яз, язъ, зъ$, ^кн, кнѧ, нѧз, ѧзь, ...</td>\n",
       "      <td>[(ть$, 0), (ьск, 1), (^см, 2), (смо, 3), (мол,...</td>\n",
       "      <td>[(ть$, 0.25), (ьск, 0.2504646840148699), (^см,...</td>\n",
       "      <td>{'^': [-0.055086426, -0.08944464, 0.04098061, ...</td>\n",
       "      <td>4.500708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lect                                            n_grams  \\\n",
       "0  Novgorod  [^се, се$, ^яз, язъ, зъ$, ^кн, кня, няз, язь, ...   \n",
       "1   Polotsk  [^ⴕ$, ^по, пок, окл, кло, лон, онъ, нъ$, ^бл, ...   \n",
       "2  Smolensk  [^се, се$, ^яз, язъ, зъ$, ^кн, кнѧ, нѧз, ѧзь, ...   \n",
       "\n",
       "                          frequency_arranged_n_grams  \\\n",
       "0  [(оро, 0), (^по, 1), (ть$, 2), (нов, 3), (мъ$,...   \n",
       "1  [(^по, 0), (ти$, 1), (пол, 2), (мъ$, 3), (^пр,...   \n",
       "2  [(ть$, 0), (ьск, 1), (^см, 2), (смо, 3), (мол,...   \n",
       "\n",
       "                          relative_frequency_n_grams  \\\n",
       "0  [(оро, 0.25), (^по, 0.2504887585532747), (ть$,...   \n",
       "1  [(^по, 0.25), (ти$, 0.2504916420845624), (пол,...   \n",
       "2  [(ть$, 0.25), (ьск, 0.2504646840148699), (^см,...   \n",
       "\n",
       "                                        lect_vectors  lect_info  \n",
       "0  {'^': [0.13765854, -0.04985554, -0.09496442, -...   4.585542  \n",
       "1  {'^': [0.00029285578, -0.17601506, -0.08750519...   4.511540  \n",
       "2  {'^': [-0.055086426, -0.08944464, 0.04098061, ...   4.500708  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f2Cvp07CCry"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE9YpEaxM0TV"
   },
   "source": [
    "First step is to introduce a measure for hybridisation.\n",
    "\n",
    "One possible measure is scoring Euclidean distance between sum of letter vectors for each n-gram. This results in a loss of order within n-gram, which can yield possible disadvantages (bra === bar), when the measure is used alone; however, when joined with DistRank and Jaro distance, hopefully they yield better results.\n",
    "\n",
    "Optional normalisation includes using alphabet information difference, calculated via subtraction of the second alphabet information from the first one. This allows to compensate for the cases, when letter from one alphabet may have multiple correspondences in the other, depending on the context. Direct (and not reversed, `1 - X`) measure is better, because the more information one alphabet carries, when contrasted to the other, the more possible one-to-many correspondences there are, the more distortions in vectors there are, the more normalisation is needed.\n",
    "\n",
    "Final normalisation includes traditional split by maximal length of two strings, introduced in Holman et al. (2008)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "id": "CxS7yw4avQkI"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.distance_measurement.string_similarity import *\n",
    "from corpus_distance.distance_measurement.hybridisation import HybridisationParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "id": "NrFVaCdmvH7M"
   },
   "outputs": [],
   "source": [
    "# assigning global values\n",
    "# group of languages  and its outgroup\n",
    "GROUP = \"Old East Slavic\"\n",
    "OUTGROUP = \"Novgorod\"\n",
    "\n",
    "# if hybrid metrics aids DistRank\n",
    "HYBRIDISATION = True\n",
    "# if hybrid values join DistRank values in a single array, or they both are\n",
    "# independent values, equally contributing to the final metric\n",
    "HYBRIDISATION_AS_ARRAY = True\n",
    "\n",
    "# if distrank normalisation includes soerensen coefficient\n",
    "SOERENSEN_NORMALISATION = True\n",
    "\n",
    "# choose a metric for hybridisation\n",
    "HYBRID = weighted_jaro_winkler_wrapper\n",
    "\n",
    "# if string similarity measure includes correction by\n",
    "# difference in the information that alphabets carry\n",
    "ALPHABET_NORMALISATION = True\n",
    "\n",
    "# metric description\n",
    "METRICS = f\"{GROUP}-{SPLIT}-{TOPIC_NORMALISATION}-DistRank-{SOERENSEN_NORMALISATION}-{HYBRIDISATION}-{HYBRIDISATION_AS_ARRAY}-{HYBRID.__name__}-{ALPHABET_NORMALISATION}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "id": "DsK5tj2ewfgL"
   },
   "outputs": [],
   "source": [
    "hybridisation_parameters = HybridisationParameters(HYBRIDISATION, SOERENSEN_NORMALISATION, HYBRIDISATION_AS_ARRAY, HYBRID, ALPHABET_NORMALISATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EJY_Rn-DiLTz",
    "outputId": "8a1a9fa1-4838-433d-cccd-96b01540b9d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Old East Slavic-1-True-DistRank-True-True-True-weighted_jaro_winkler_wrapper-True'"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "id": "0bdWdnbAv1gE"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.distance_measurement.metrics_pipeline import score_metrics_for_corpus_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xOwwG54CEJD",
    "outputId": "ddfabedf-72ab-4a34-8919-1bf65bf3539f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1077/1077 [00:00<00:00, 2902.32it/s]\n",
      "100%|██████████| 635/635 [00:10<00:00, 60.04it/s]\n",
      "100%|██████████| 582/582 [00:10<00:00, 53.52it/s]\n",
      "100%|██████████| 1077/1077 [00:00<00:00, 2891.37it/s]\n",
      "100%|██████████| 648/648 [00:10<00:00, 60.17it/s]\n",
      "100%|██████████| 589/589 [00:11<00:00, 51.61it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 3508.20it/s]\n",
      "100%|██████████| 637/637 [00:10<00:00, 58.03it/s]\n",
      "100%|██████████| 631/631 [00:11<00:00, 57.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# declare arrays\n",
    "# calculate distances for each pair of lects\n",
    "overall_results = score_metrics_for_corpus_dataset(df_new, \"/home/ilia/Дакументы/vector_analysis/experiment_results/exp_233\", METRICS, hybridisation_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkJIqBNM0tUt"
   },
   "source": [
    "# Clusterisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FX8ByiTMiQiE"
   },
   "source": [
    "The final step is to cluster the lects into groups, and to decide, whether the method works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "id": "OsBu1_Og0wD9"
   },
   "outputs": [],
   "source": [
    "from corpus_distance.clusterisation.clusterisation import ClusterisationParameters, clusterise_lects_from_distance_matrix\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "id": "m6v_o5hq1LYS"
   },
   "outputs": [],
   "source": [
    "cluster_params = ClusterisationParameters(lects, OUTGROUP, GROUP, METRICS, DistanceTreeConstructor().upgma, \"/home/ilia/Дакументы/vector_analysis/experiment_results/exp_233\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "id": "5-EL_T3Q7Dwt"
   },
   "outputs": [],
   "source": [
    "clusterise_lects_from_distance_matrix(overall_results, cluster_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lemmatiser-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
